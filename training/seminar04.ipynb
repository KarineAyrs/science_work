{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ8j45AJoHXV"
   },
   "source": [
    "# Практическое задание\n",
    "\n",
    "## Данные о студенте\n",
    "\n",
    "1. **ФИО**: Айрапетьянц Каринэ Арсеновна\n",
    "2. **Факультет**: ВМК\n",
    "3. **Курс**: 5\n",
    "4. **Группа**: 519/2\n",
    "\n",
    "## Замечания\n",
    "\n",
    "* Заполненный ноутбук необходимо сдать боту\n",
    "* Соблюдаем кодекс чести (по нулям и списавшему, и давшему списать)\n",
    "* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\n",
    "* Ничего, крому Numpy, нельзя использовать для реализации \n",
    "* **Keras** используется только для тестирования Вашей реализации\n",
    "* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\n",
    "* Возможно использование дополнительных (приватных) тестов\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gFbdRxRoHXY"
   },
   "source": [
    "## Реализация собственного нейросетевого пакета для запуска и обучения нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R74m-dAoHXZ"
   },
   "source": [
    "Задание состоит из трёх частей:\n",
    "1. Реализация прямого вывода нейронной сети (5 баллов)\n",
    "2. Реализация градиентов по входу и распространения градиента по сети (5 баллов)\n",
    "3. Реализация градиентов по параметрам и метода обратного распространения ошибки с обновлением парметров сети (10 баллов)\n",
    "\n",
    "Дополнительные баллы можно получить при реализации обучения сети со свёрточными слоями (10 баллов), с транспонированной свёрткой (10 баллов), дополнительного оптимизатора (5 баллов). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPi7PuipoHXZ"
   },
   "source": [
    "###  1. Реализация вывода собственной нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmGsHLDRoHXZ"
   },
   "source": [
    "1.1 Внимательно ознакомьтесь с интерфейсом слоя. Любой слой должен содержать как минимум три метода:\n",
    "- конструктор\n",
    "- прямой вывод \n",
    "- обратный вывод, производные по входу и по параметрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1648722535363,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "EtTL3HcCoHXa"
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'Layer'       \n",
    "    def forward(self, input_data):\n",
    "        pass\n",
    "    def backward(self, input_data):\n",
    "        return [self.grad_x(input_data), self.grad_param(input_data)]\n",
    "    \n",
    "    def grad_x(self, input_data):\n",
    "        pass\n",
    "        \n",
    "    def grad_param(self, input_data):\n",
    "        return []\n",
    "    \n",
    "    def update_param(self, grads, learning_rate):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB5RsEjwoHXb"
   },
   "source": [
    "1.2 Ниже предствален интерфейс класса  Network. Обратите внимание на реализацию метода predict, который последовательно обрабатывает входные данные слой за слоем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1648722536253,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "yPJBdAzmoHXb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Network(object):\n",
    "    def __init__(self, layers, loss=None):\n",
    "        self.name = 'Network'\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.predict(input_data)\n",
    "\n",
    "    def grad_x(self, input_data, labels):\n",
    "        \n",
    "        # curr_data = self.loss.grad_x(self.forward(input_data), labels)\n",
    "        # derivs = [curr_data]\n",
    "        #\n",
    "        # for i in range(len(self.layers) - 1, -1, -1):\n",
    "        #     curr_data = self.layers[i].grad_x(curr_data)\n",
    "        #     derivs.append(curr_data)\n",
    "        #\n",
    "        # \n",
    "\n",
    "        n = len(self.layers)\n",
    "        derivs = [[] for i in range(n + 1)]\n",
    "        j = n\n",
    "\n",
    "        curr_data = input_data\n",
    "        for layer in self.layers:\n",
    "            derivs[j] = layer.grad_x(curr_data)\n",
    "            curr_data = layer.forward(curr_data)\n",
    "            j -= 1\n",
    "\n",
    "        derivs[j] = self.loss.grad_x(curr_data, labels)\n",
    "        \n",
    "        \n",
    "        der = self.__calc_der(derivs, -1, input_data.shape[0])\n",
    "        return der\n",
    "    \n",
    "\n",
    "    def grad_param(self, input_data, labels):\n",
    "        \n",
    "        n = len(self.layers)\n",
    "        p_grads, p, d = [], [], [[] for i in range(n + 1)]\n",
    "        j = n\n",
    "\n",
    "        curr_data = input_data\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            d[j] = layer.grad_x(curr_data)\n",
    "            next_data = layer.forward(curr_data)\n",
    "            p.append(layer.grad_param(curr_data))\n",
    "            curr_data = next_data\n",
    "            j -= 1\n",
    "\n",
    "        d[j] = self.loss.grad_x(curr_data, labels)\n",
    "\n",
    "        for i, p_grad in enumerate(p):\n",
    "            if len(p_grad) != 0:\n",
    "                der = self.__calc_der(d, i, input_data.shape[0])\n",
    "\n",
    "                der = np.expand_dims(der, 1)\n",
    "\n",
    "                for b in range(input_data.shape[0]):\n",
    "                    for g in range(len(p_grad)):\n",
    "                        p_grad[g][b] = np.dot(der[b], p_grad[g][b])\n",
    "            p_grads.append(p_grad)\n",
    "\n",
    "        return p_grads\n",
    "\n",
    "\n",
    "    def update(self, grad_list, learning_rate):\n",
    "        for i in range(len(self.layers)):\n",
    "            self.layers[i].update_param(grad_list[i], learning_rate)\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        current_input = input_data\n",
    "        for layer in self.layers:\n",
    "            current_input = layer.forward(current_input)\n",
    "        return current_input\n",
    "\n",
    "    def calculate_loss(self, input_data, labels):\n",
    "        return self.loss.forward(self.forward(input_data), labels)\n",
    "\n",
    "    def train_step(self, input_data, labels, learning_rate=0.001):\n",
    "        grad_list = self.grad_param(input_data, labels)\n",
    "        self.update(grad_list, learning_rate)\n",
    "\n",
    "    def fit(self, trainX, trainY, validation_split=0.25,\n",
    "            batch_size=1, nb_epoch=1, learning_rate=0.01):\n",
    "\n",
    "        train_x, val_x, train_y, val_y = train_test_split(trainX, trainY,\n",
    "                                                          test_size=validation_split,\n",
    "                                                          random_state=42)\n",
    "        for epoch in range(nb_epoch):\n",
    "            # train one epoch\n",
    "            for i in tqdm(range(int(len(train_x) / batch_size))):\n",
    "                batch_x = train_x[i * batch_size: (i + 1) * batch_size]\n",
    "                batch_y = train_y[i * batch_size: (i + 1) * batch_size]\n",
    "                self.train_step(batch_x, batch_y, learning_rate)\n",
    "            # validate\n",
    "            val_accuracy = self.evaluate(val_x, val_y)\n",
    "            print('%d epoch: val %.2f' % (epoch + 1, val_accuracy))\n",
    "\n",
    "    def evaluate(self, testX, testY):\n",
    "        y_pred = np.argmax(self.predict(testX), axis=1)\n",
    "        y_true = np.argmax(testY, axis=1)\n",
    "        val_accuracy = np.sum((y_pred == y_true)) / (len(y_true))\n",
    "        return val_accuracy\n",
    "\n",
    "    \n",
    "    def __calc_der(self, derivs, k, n):\n",
    "        der = []\n",
    "        for b in range(n):\n",
    "            der.append(derivs[0][b])\n",
    "            for j in range(1, len(derivs) - k - 1, 1):\n",
    "                der[b] = np.dot(der[b], derivs[j][b])\n",
    "\n",
    "        return np.array(der)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Koy6B2SBoHXc"
   },
   "source": [
    "#### 1.1 Необходимо реализовать метод forward для вычисления следующих слоёв:\n",
    "\n",
    "- DenseLayer\n",
    "- ReLU\n",
    "- Softmax\n",
    "- FlattenLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648722536254,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "cTkQpJqXoHXd"
   },
   "outputs": [],
   "source": [
    "#импорты\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648722536254,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "g3HIrURKoHXd"
   },
   "outputs": [],
   "source": [
    "class DenseLayer(Layer):\n",
    "    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\n",
    "        super().__init__()\n",
    "        self.name = 'Dense'\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        if W_init is None or b_init is None:\n",
    "            lecun_init = np.sqrt(3) / np.sqrt(input_dim)\n",
    "            self.W = np.random.uniform(-lecun_init, lecun_init, (input_dim, output_dim))\n",
    "            self.b = np.zeros(output_dim, 'float32')\n",
    "        else:\n",
    "            self.W = W_init\n",
    "            self.b = b_init\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return input_data@self.W + self.b\n",
    "\n",
    "    def grad_x(self, input_data):\n",
    "        res = []\n",
    "        for b in range(input_data.shape[0]):\n",
    "            res.append(self.W.T)\n",
    "        return np.array(res)\n",
    "\n",
    "    def grad_b(self, input_data):\n",
    "        res = []\n",
    "        for b in range(input_data.shape[0]):\n",
    "            res.append(np.eye(self.output_dim))\n",
    "        return np.array(res)\n",
    "\n",
    "    def grad_W(self, input_data):\n",
    "        # медленно!\n",
    "        # res=[]\n",
    "        # for x in input_data:\n",
    "        #     inter_res = []\n",
    "        #     for el in x:\n",
    "        #         to_concat = np.diag(np.ones(len(x))*el)\n",
    "        #         if len(inter_res) == 0:\n",
    "        #             inter_res = to_concat\n",
    "        #             continue\n",
    "        #         inter_res = np.concatenate((inter_res, to_concat), axis=1)\n",
    "        #\n",
    "        #     res.append(inter_res)\n",
    "\n",
    "        # return np.array(res)\n",
    "\n",
    "        res = np.zeros((input_data.shape[0], self.output_dim, self.input_dim * self.output_dim))\n",
    "\n",
    "        for b in range(input_data.shape[0]):\n",
    "            for i in range(self.output_dim):\n",
    "                for j in range(self.input_dim):\n",
    "                    res[b][i][i + j * self.output_dim] = input_data[b][j]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def update_W(self, grad, learning_rate):\n",
    "        for b in range(grad.shape[0]):\n",
    "            self.W -= learning_rate * np.mean(grad[b], axis=0).reshape(self.W.shape)\n",
    "\n",
    "    def update_b(self, grad, learning_rate):\n",
    "        for bt in range(grad.shape[0]):\n",
    "            self.b -= learning_rate * np.mean(grad[bt], axis=0)\n",
    "\n",
    "    def update_param(self, params_grad, learning_rate):\n",
    "        self.update_W(params_grad[0], learning_rate)\n",
    "        self.update_b(params_grad[1], learning_rate)\n",
    "\n",
    "    def grad_param(self, input_data):\n",
    "        return [self.grad_W(input_data), self.grad_b(input_data)]\n",
    "\n",
    "\n",
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = 'ReLU'\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return np.maximum(input_data, 0)\n",
    "\n",
    "    def grad_x(self, input_data):\n",
    "        derivs = np.where(input_data > 0, 1.0, 0.0)\n",
    "        return np.asarray([np.diag(der) for der in derivs])\n",
    "\n",
    "\n",
    "class Softmax(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = 'Softmax'\n",
    "\n",
    "    def forward(self, input_data): \n",
    "        return np.array([np.exp(input_data[b]) / np.sum(np.exp(input_data[b])) for b in range(input_data.shape[0])])\n",
    "\n",
    "    def grad_x(self, input_data):        \n",
    "        # s'= s(x_i)-s(x_i)s(x_j), i=j || 0-s(x_i)s(x_j), i!=j => diag(s)-[s(x_i)s(x_j)], i=1,..n, j=1,..,n\n",
    "        input_data = self.forward(input_data)\n",
    "        res = []\n",
    "        for b in range(input_data.shape[0]):\n",
    "            res.append(np.diag(input_data[b]) - np.outer(input_data[b], input_data[b]))        \n",
    "        return np.array(res)\n",
    "\n",
    "\n",
    "class FlattenLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = 'Flatten'\n",
    "        self._prev_shape = None\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self._prev_shape = input_data.shape\n",
    "        return np.reshape(input_data, (input_data.shape[0], -1))\n",
    "\n",
    "    def grad_x(self, input_data):\n",
    "        return np.reshape(input_data, self._prev_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVW8bd1EoHXd"
   },
   "source": [
    "#### 1.2 Реализуйте теперь свёрточный слой и транспонированную свёртку  (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLh-N408oHXd"
   },
   "source": [
    "#### Для сверточного слоя успела реализовать только прямой проход и его тестирование. \n",
    "\n",
    "Напоминание: 'same' padding: $2p=(W-1)s-W+ksize$, аналогично для $H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1648722536254,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "FVxEBmFFoHXe"
   },
   "outputs": [],
   "source": [
    "class Conv2DLayer(Layer):\n",
    "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
    "                 padding='same', stride=1, K_init=None, b_init=None):\n",
    "        # padding: 'same' или 'valid'\n",
    "        # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "        # Работаем с единообразным сдвигом, поэтому stride - одно число\n",
    "        # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "        self.name = 'Conv2D'\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel = K_init\n",
    "        self.bias = b_init\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        # На входе - четырехмерный тензор вида [batch, height, width, input_channels]\n",
    "        # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "        # Нужно заполнить Numpy-тензор out \n",
    "            \n",
    "\n",
    "        assert input_data.shape[3]==self.kernel.shape[2], 'Input in_channels!=kernel in_channels!'\n",
    "        \n",
    "    \n",
    "        def calc_conv(tensor, out_size, steps):\n",
    "            \n",
    "            Y = np.zeros((tensor.shape[0], out_size[0], out_size[1], self.output_channels))\n",
    "\n",
    "            for batch in range(tensor.shape[0]):\n",
    "\n",
    "                for cout in range(self.output_channels):  \n",
    "                    \n",
    "                    cards = np.zeros((out_size[0], out_size[1], self.input_channels))\n",
    "\n",
    "                    for cin in range(self.input_channels):\n",
    "                        \n",
    "                        card = np.zeros((out_size[0], out_size[1]))\n",
    "                        \n",
    "                        for i in range(steps[0]): \n",
    "                            for j in range(steps[1]):  \n",
    "                                to_mul = tensor[batch,i*self.stride:self.kernel_size+i*self.stride,\n",
    "                                                j*self.stride:self.kernel_size+j*self.stride,cin]\n",
    "                                card[i][j] = np.sum(to_mul*self.kernel[:,:,cin,cout])\n",
    "\n",
    "\n",
    "                        cards[:,:,cin] = card\n",
    "\n",
    "                    Y[batch,:,:,cout]=np.sum(cards, axis=2)+self.bias[cout] \n",
    "\n",
    "            return Y \n",
    "       \n",
    "    \n",
    "        \n",
    "        H, W = input_data.shape[1], input_data.shape[2]\n",
    "       \n",
    "        if self.padding=='valid':\n",
    "\n",
    "            H_out = int((H-self.kernel_size)/self.stride+1)\n",
    "            W_out = int((W-self.kernel_size)/self.stride+1)\n",
    "\n",
    "            return calc_conv(input_data,(H_out, W_out), (H_out, W_out))\n",
    "\n",
    "\n",
    "        if self.padding=='same':\n",
    "          \n",
    "            p_W=((W-1)*self.stride-W+self.kernel_size) \n",
    "            p_H=((H-1)*self.stride-H+self.kernel_size)\n",
    "\n",
    "            pad_top = int(p_H//2)\n",
    "            pad_bottom = int(p_H - pad_top) \n",
    "            pad_left = int(p_W//2)              \n",
    "            pad_right = int(p_W - pad_left)\n",
    "\n",
    "        \n",
    "            padded_tensor = np.zeros((input_data.shape[0], input_data.shape[1] + int(p_H), \n",
    "                                      input_data.shape[2] + int(p_W), input_data.shape[3]))\n",
    "\n",
    "            padded_tensor[:,pad_top:-pad_bottom, pad_left:-pad_right, :] = input_data\n",
    "\n",
    "\n",
    "            H_steps = int((padded_tensor.shape[1]-self.kernel_size)/self.stride+1)    \n",
    "            W_steps = int((padded_tensor.shape[2]-self.kernel_size)/self.stride+1)\n",
    "\n",
    "            return calc_conv(padded_tensor, (H,W), (H_steps, W_steps))\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    def grad_x(self, input_data):\n",
    "        pass\n",
    "    def grad_kernel(self, input_data):\n",
    "        pass\n",
    "        \n",
    "    def grad_param(self, input_data):\n",
    "        return [self.grad_kernel(input_data)]\n",
    "    \n",
    "    def update_param(self, grads, learning_rate):   \n",
    "        # smth like this \n",
    "        self.kernel-=learning_rate*np.mean(grads[0], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1648722536655,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "FH0md1gXoHXe"
   },
   "outputs": [],
   "source": [
    "class Conv2DTrLayer(Layer):\n",
    "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
    "                 padding=0, stride=1, K_init=None, b_init=None):      \n",
    "        # padding: число (сколько отрезать от модифицированной входной карты)\n",
    "        # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "        # stride - одно число (коэффициент расширения)\n",
    "        # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "        self.name = 'Conv2DTr'\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel = K_init\n",
    "        self.bias = b_init\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "        # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "        # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "        # Нужно заполнить Numpy-тензор out \n",
    "        out = np.empty([])\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def grad_x(self):\n",
    "        pass\n",
    "    def grad_kernel(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxRNxRr2oHXf"
   },
   "source": [
    "#### 1.4 Теперь настало время теста. \n",
    "#### Если вы всё сделали правильно, то запустив следующие ячейки у вас должна появиться надпись: Test PASSED\n",
    "\n",
    "Переходить к дальнейшим заданиям не имеем никакого смысла, пока вы не добьётесь прохождение теста\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3hkn4gooHXf"
   },
   "source": [
    "#### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1648722537209,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "UWNnnzwcoHXf",
    "outputId": "111a4d51-1510-4f73-858b-0c6568c94fe0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 16:22:39.397464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-11 16:22:39.397491: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (60000, 10) (10000, 1, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    " \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A8bl193oHXg"
   },
   "source": [
    "#### Подготовка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1648722537209,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "mt71QhU7oHXg",
    "outputId": "d3605290-ca68-43da-a21c-ba79d6b8cca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import gradient_descent_v2\n",
    "print(keras.__version__)\n",
    "\n",
    "def get_keras_model():\n",
    "    input_image = Input(shape=(1, 28, 28))\n",
    "    flatten = Flatten()(input_image)\n",
    "    dense1 = Dense(10, activation='softmax')(flatten)\n",
    "    \n",
    "    model = Model(inputs=input_image, outputs=dense1)\n",
    "\n",
    "    sgd = gradient_descent_v2.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, validation_split=0.25, \n",
    "                        batch_size=32, epochs=2, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648722537209,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "eD6OuviEoHXg"
   },
   "outputs": [],
   "source": [
    "def get_our_model(keras_model):\n",
    "    flatten = FlattenLayer()\n",
    "    dense = DenseLayer(784, 10, W_init=keras_model.get_weights()[0],\n",
    "                       b_init=keras_model.get_weights()[1])\n",
    "    softmax = Softmax()\n",
    "    net = Network([flatten, dense, softmax])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8041,
     "status": "ok",
     "timestamp": 1648722545247,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "AVuThdsLoHXh",
    "outputId": "6396b257-595d-441f-a422-45ca859623b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 18:41:16.081352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 18:41:16.081689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-01 18:41:16.081752: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-01 18:41:16.081804: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-01 18:41:16.081855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-04-01 18:41:16.081904: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-04-01 18:41:16.081955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-01 18:41:16.082004: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-01 18:41:16.082053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-04-01 18:41:16.082062: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-01 18:41:16.082646: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-01 18:41:16.109268: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 141120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 2s 997us/step - loss: 0.4476 - accuracy: 0.8781 - val_loss: 0.3339 - val_accuracy: 0.9061\n",
      "Epoch 2/2\n",
      "1407/1407 [==============================] - 1s 661us/step - loss: 0.3250 - accuracy: 0.9085 - val_loss: 0.3062 - val_accuracy: 0.9151\n"
     ]
    }
   ],
   "source": [
    "keras_model = get_keras_model()\n",
    "our_model = get_our_model(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1648722546457,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "FfVvDETdoHXh"
   },
   "outputs": [],
   "source": [
    "keras_prediction = keras_model.predict(X_test)\n",
    "our_model_prediction = our_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648722546458,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "euj6FJvKoHXh",
    "outputId": "aded3d83-87f7-4b64-c4c0-15fa0fd9c697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "if np.sum(np.abs(keras_prediction - our_model_prediction)) < 0.01:\n",
    "    print('Test PASSED')\n",
    "else:\n",
    "    print('Something went wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0fWrP9tXe2O"
   },
   "source": [
    "#### Тестирование сети со сверточным слоем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648722546458,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "cY2s0dlVEW9j"
   },
   "outputs": [],
   "source": [
    "X_train_conv = X_train.reshape((X_train.shape[0], X_train.shape[2], X_train.shape[3], X_train.shape[1]))\n",
    "X_test_conv = X_test.reshape((X_test.shape[0], X_test.shape[2], X_test.shape[3], X_test.shape[1]))[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648722546458,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "7YmR3wxMvx7m"
   },
   "outputs": [],
   "source": [
    "def get_keras_conv_model():\n",
    "    input_image = Input(shape=(28, 28, 1))\n",
    "    conv2d = Conv2D(filters=3, \n",
    "                    kernel_size=3, \n",
    "                    strides=1, \n",
    "                    padding='same')(input_image)\n",
    "                    \n",
    "    flatten = Flatten()(conv2d)\n",
    "    dense1 = Dense(10, activation='softmax')(flatten)\n",
    "    model = Model(inputs=input_image, outputs=dense1)\n",
    "\n",
    "    sgd = gradient_descent_v2.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train_conv, Y_train, validation_split=0.25, \n",
    "                        batch_size=32, epochs=2, verbose=1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648722546458,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "mCFugT6PwxVQ"
   },
   "outputs": [],
   "source": [
    "def get_our_conv_model(keras_model):\n",
    "    conv2d=Conv2DLayer(kernel_size=3, \n",
    "                       input_channels=1, \n",
    "                       output_channels=3, \n",
    "                       padding='same', \n",
    "                       stride=1,\n",
    "                       K_init=keras_model.get_weights()[0],\n",
    "                       b_init=keras_model.get_weights()[1])\n",
    "    \n",
    "    flatten = FlattenLayer()\n",
    "    dense = DenseLayer(2352, 10, \n",
    "                       W_init=keras_model.get_weights()[2],\n",
    "                       b_init=keras_model.get_weights()[3])\n",
    "    softmax = Softmax()\n",
    "    net = Network([conv2d, flatten, dense, softmax])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42086,
     "status": "ok",
     "timestamp": 1648722588537,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "jrGOMKzW_p3w",
    "outputId": "bab515f1-1718-4941-f0f3-324a005ef270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 18:41:19.226046: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 141120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8906 - val_loss: 0.3126 - val_accuracy: 0.9113\n",
      "Epoch 2/2\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 0.3111 - accuracy: 0.9108 - val_loss: 0.3119 - val_accuracy: 0.9114\n"
     ]
    }
   ],
   "source": [
    "keras_model = get_keras_conv_model()\n",
    "our_model = get_our_conv_model(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 53251,
     "status": "ok",
     "timestamp": 1648722641779,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "RBKebHo9xNHM"
   },
   "outputs": [],
   "source": [
    "keras_prediction = keras_model.predict(X_test_conv)\n",
    "our_model_prediction = our_model.predict(X_test_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1648722641781,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "Le8t7TwfxPdJ",
    "outputId": "d7927918-9b75-4387-964d-42043b6f72f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "if np.sum(np.abs(keras_prediction - our_model_prediction)) < 0.01:\n",
    "    print('Test PASSED')\n",
    "else:\n",
    "    print('Something went wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FHsGr6RoHXh"
   },
   "source": [
    "### 2. Вычисление производных по входу для слоёв нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_r_Qbe7oHXh"
   },
   "source": [
    "В данном задании запрещено использовать численные формулы для вычисления производных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocwPLQqZoHXi"
   },
   "source": [
    "#### 2.1  Реализуйте метод forward для класса CrossEntropy\n",
    "Напоминание: $$ crossentropy = L(p, y) =  - \\sum\\limits_i y_i log p_i, $$\n",
    "где вектор $(p_1, ..., p_k) $ -  выход классификационного алгоритма, а $(y_1,..., y_k)$ - правильные метки класса в унарной кодировке (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1648722641782,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "FTPI1wg2oHXi"
   },
   "outputs": [],
   "source": [
    "class CrossEntropy(object):\n",
    "    def __init__(self, eps=0.00001):\n",
    "        self.name = 'CrossEntropy'\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input_data, labels):\n",
    "        return -np.sum((np.multiply(np.log(input_data), labels)), axis=1)\n",
    "\n",
    "    def calculate_loss(self, input_data, labels):\n",
    "        return self.forward(input_data, labels)\n",
    "\n",
    "    def grad_x(self, input_data, labels):\n",
    "        return -labels / (input_data + self.eps)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZnh9N-YoHXi"
   },
   "source": [
    "#### 2.2  Реализуйте метод grad_x класса CrossEntropy, который возвращает $\\frac{\\partial L}{\\partial p}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvkueQ34oHXi"
   },
   "source": [
    "Проверить работоспособность кода поможет следующий тест:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1648722641783,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "hY9Ji5fRoHXi",
    "outputId": "5cbbb38e-da0c-4cd3-f859-66766d296692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "def numerical_diff_net(net, x, labels):\n",
    "    eps = 0.00001\n",
    "    right_answer = []\n",
    "    for i in range(len(x[0])):\n",
    "        delta = np.zeros(len(x[0]))\n",
    "        delta[i] = eps\n",
    "        diff = (net.calculate_loss(x + delta, labels) - net.calculate_loss(x-delta, labels)) / (2*eps)\n",
    "        right_answer.append(diff)\n",
    "    return np.array(right_answer).T\n",
    "\n",
    "def test_net(net):\n",
    "    x = np.array([[1, 2, 3], [2, 3, 4]])\n",
    "    labels = np.array([[0.3, 0.2, 0.5], [0.3, 0.2, 0.5]])\n",
    "    num_grad = numerical_diff_net(net, x, labels)\n",
    "    grad = net.grad_x(x, labels)\n",
    "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
    "        print('Test PASSED')\n",
    "    else:\n",
    "        print('Something went wrong!')\n",
    "        print('Numerical grad is')\n",
    "        print(num_grad)\n",
    "        print('Your gradiend is ')\n",
    "        print(grad)\n",
    "        \n",
    "loss = CrossEntropy()\n",
    "test_net(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN7vmvM4oHXj"
   },
   "source": [
    "#### 2.3  Реализуйте метод grad_x класса Softmax, который возвращает $\\frac{\\partial Softmax}{\\partial x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydAJ3T-HoHXj"
   },
   "source": [
    "Проверить работоспособность кода поможет следующий тест:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1648722641784,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "zOSBmgDPoHXj",
    "outputId": "88e13349-3fe8-423e-a040-e2e17b78cd5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "def numerical_diff_layer(layer, x):\n",
    "    eps = 0.00001\n",
    "    right_answer = []\n",
    "    for i in range(len(x[0])):\n",
    "        delta = np.zeros(len(x[0]))\n",
    "        delta[i] = eps\n",
    "        diff = (layer.forward(x + delta) - layer.forward(x-delta)) / (2*eps)\n",
    "        right_answer.append(diff.T)\n",
    "    return np.array(right_answer).T\n",
    "\n",
    "def test_layer(layer):\n",
    "    x = np.array([[1, 2, 3], [2, -3, 4]])\n",
    "    num_grad = numerical_diff_layer(layer, x)\n",
    "    grad = layer.grad_x(x)\n",
    "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
    "        print('Test PASSED')\n",
    "    else:\n",
    "        print('Something went wrong!')\n",
    "        print('Numerical grad is')\n",
    "        print(num_grad)\n",
    "        print('Your gradiend is ')\n",
    "        print(grad)\n",
    "        \n",
    "layer = Softmax()\n",
    "test_layer(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJr_6REyoHXj"
   },
   "source": [
    "#### 2.4  Реализуйте метод grad_x для классов ReLU и DenseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1648722642285,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "LsiQPmTGoHXj",
    "outputId": "77983687-63ad-4905-dcd1-4eaaa416f425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "layer = ReLU()\n",
    "test_layer(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1648722642287,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "aO5mlu9aoHXj",
    "outputId": "254ce0b8-6782-4054-bcbb-8786e0a30222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "layer = DenseLayer(3,4)\n",
    "test_layer(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0HXOp5XoHXk"
   },
   "source": [
    "#### 2.5 (4 балла) Для класса Network реализуйте метод grad_x, который должен реализовывать взятие производной от лосса по входу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1648722642288,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "otY7KI4DoHXk",
    "outputId": "dd085a05-0e25-4b0c-b53c-39df5831b22d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "net = Network([DenseLayer(3, 10), ReLU(), DenseLayer(10, 3), Softmax()], \n",
    "              loss=CrossEntropy())\n",
    "test_net(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhYr-1aPoHXk"
   },
   "source": [
    "### 3. Реализация градиентов по параметрам и метода обратного распространения ошибки с обновлением парметров сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7qkFKxCoHXk"
   },
   "source": [
    "#### 3.1  Реализуйте функции grad_b и grad_W. При подготовке теста grad_W предполагается, что W является одномерным вектором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1648722642289,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "U5pwrccgoHXk",
    "outputId": "104e845c-7393-45c3-a044-33349eb737eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "def numerical_grad_b(input_size, output_size, b, W, x):\n",
    "    eps = 0.00001\n",
    "    right_answer = []\n",
    "    for i in range(len(b)):\n",
    "        delta = np.zeros(b.shape)\n",
    "        delta[i] = eps\n",
    "        dense1 = DenseLayer(input_size, output_size, W_init=W, b_init=b+delta)\n",
    "        dense2 = DenseLayer(input_size, output_size, W_init=W, b_init=b-delta)\n",
    "        diff = (dense1.forward(x) - dense2.forward(x)) / (2*eps)\n",
    "        right_answer.append(diff.T)\n",
    "    return np.array(right_answer).T\n",
    "\n",
    "def test_grad_b():\n",
    "    input_size = 3\n",
    "    output_size = 4 \n",
    "    W_init = np.random.random((input_size, output_size))\n",
    "    b_init = np.random.random((output_size,))\n",
    "    x = np.random.random((2, input_size))\n",
    "    \n",
    "    dense = DenseLayer(input_size, output_size, W_init, b_init)\n",
    "    grad = dense.grad_b(x)\n",
    "\n",
    "    num_grad = numerical_grad_b(input_size, output_size, b_init, W_init, x)\n",
    "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
    "        print('Test PASSED')\n",
    "    else:\n",
    "        print('Something went wrong!')\n",
    "        print('Numerical grad is')\n",
    "        print(num_grad)\n",
    "        print('Your gradiend is ')\n",
    "        print(grad)\n",
    "\n",
    "test_grad_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1648722642290,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "alZflyKfoHXk",
    "outputId": "88499d2b-4499-455f-f611-e6b9880c9121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASSED\n"
     ]
    }
   ],
   "source": [
    "def numerical_grad_W(input_size, output_size, b, W, x):\n",
    "    eps = 0.00001\n",
    "    right_answer = []\n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            delta = np.zeros(W.shape)\n",
    "            delta[i, j] = eps\n",
    "            dense1 = DenseLayer(input_size, output_size, W_init=W+delta, b_init=b)\n",
    "            dense2 = DenseLayer(input_size, output_size, W_init=W-delta, b_init=b)\n",
    "            diff = (dense1.forward(x) - dense2.forward(x)) / (2*eps)\n",
    "            right_answer.append(diff.T)\n",
    "    return np.array(right_answer).T\n",
    "\n",
    "def test_grad_W():\n",
    "    input_size = 3\n",
    "    output_size = 4 \n",
    "    W_init = np.random.random((input_size, output_size))\n",
    "    b_init = np.random.random((4,))\n",
    "    x = np.random.random((2, input_size))\n",
    "        \n",
    "    dense = DenseLayer(input_size, output_size, W_init, b_init)\n",
    "    grad = dense.grad_W(x)\n",
    "\n",
    "    num_grad = numerical_grad_W(input_size, output_size, b_init, W_init, x)\n",
    "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
    "        print('Test PASSED')\n",
    "    else:\n",
    "        print('Something went wrong!')\n",
    "        print('Numerical grad is')\n",
    "        print(num_grad)\n",
    "        print('Your gradiend is ')\n",
    "        print(grad)\n",
    "\n",
    "test_grad_W()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YU2nTDTJoHXk"
   },
   "source": [
    "#### 3.2 Полностью реализуйте метод обратного распространения ошибки в функции train_step класса Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BU5T0R8qoHXk"
   },
   "source": [
    "Рекомендуем реализовать сначала функцию Network.grad_param(), которая возвращает список длиной в количество слоёв и элементом которого является список градиентов по параметрам.\n",
    "После чего, имея список градиентов, написать функцию обновления параметров для каждого слоя. \n",
    "\n",
    "Совет: рекомендуем написать тест для кода подсчета градиента по параметрам, чтобы быть уверенным в том, что градиент через всю сеть считается правильно\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46O535RtoHXl"
   },
   "source": [
    "#### 3.3 Ознакомьтесь с реализацией функции fit класса Network. Запустите обучение модели. Если всё работает правильно, то точность на валидации должна будет возрастать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 822443,
     "status": "ok",
     "timestamp": 1648723464718,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "9cu0uhdvoHXl",
    "outputId": "ceeac115-3b20-453c-c6cc-6dcedfdf9d50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 937/937 [02:04<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch: val 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 937/937 [02:04<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch: val 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 937/937 [02:04<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch: val 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 937/937 [02:04<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch: val 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 937/937 [02:04<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch: val 0.92\n"
     ]
    }
   ],
   "source": [
    "net = Network([DenseLayer(784, 10), Softmax()], loss=CrossEntropy())\n",
    "trainX = X_train.reshape(len(X_train), -1)\n",
    "net.fit(trainX[::3], Y_train[::3], validation_split=0.25, \n",
    "            batch_size=16, nb_epoch=5, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 718967,
     "status": "ok",
     "timestamp": 1648724183672,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "d5jFHhHJoHXl",
    "outputId": "77b0d427-66ae-4cf2-9140-31d4ebcb5c11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [01:34<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch: val 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [01:35<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch: val 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [01:34<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch: val 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [01:34<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch: val 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [01:34<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch: val 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = Network([DenseLayer(784, 20), ReLU(), DenseLayer(20, 10), Softmax()], loss=CrossEntropy())\n",
    "trainX = X_train.reshape(len(X_train), -1)\n",
    "net.fit(trainX[::6], Y_train[::6], validation_split=0.25, \n",
    "            batch_size=16, nb_epoch=5, learning_rate=0.001)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSLRTDwLoHXl"
   },
   "source": [
    "#### 3.5 Продемонстрируйте, что ваша реализация позволяет обучать более глубокие нейронные сети "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1879788,
     "status": "ok",
     "timestamp": 1648726063412,
     "user": {
      "displayName": "Каринэ Айрапетьянц",
      "userId": "17456633980558259767"
     },
     "user_tz": -120
    },
    "id": "BI5leexYoHXl",
    "outputId": "77f7fd5f-c310-45d2-c213-9fc0e056a3ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [03:45<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch: val 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [03:44<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch: val 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [03:43<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch: val 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [03:43<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch: val 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 468/468 [03:43<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch: val 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = Network([DenseLayer(784, 50), \n",
    "               ReLU(), \n",
    "               DenseLayer(50, 20), \n",
    "               ReLU(), \n",
    "               DenseLayer(20, 10), \n",
    "               Softmax()], loss=CrossEntropy())\n",
    "\n",
    "trainX = X_train.reshape(len(X_train), -1)\n",
    "net.fit(trainX[::6], Y_train[::6], validation_split=0.25, \n",
    "            batch_size=16, nb_epoch=5, learning_rate=0.001)    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "seminar04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
