{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "improved_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPx/JR8BcnU8TP+8+eSk2/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarineAyrs/science_work/blob/main/training/improved_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5L20GrQjTge"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_zKwatCjVjx"
      },
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ79FH68jZEW"
      },
      "source": [
        "\n",
        "class TimmModel(nn.Module):\n",
        "\n",
        "    def __init__(self, model_name='efficientnet_b0', pretrained=True):\n",
        "\n",
        "        super(TimmModel, self).__init__()\n",
        "        self._model_name = model_name\n",
        "        self._pretrained = pretrained\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = timm.create_model(model_name=model_name, pretrained=pretrained)\n",
        "        self.model.train()\n",
        "        if torch.cuda.is_available():\n",
        "            self.model.cuda()\n",
        "\n",
        "    def model_config(self, learning_rate=0.001, batch_size=2, num_epochs=5, criterion=None, optimizer=None):\n",
        "        self.lr = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = 5\n",
        "        self.criterion = nn.CrossEntropyLoss() if criterion is None else criterion\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate) if optimizer is None else optimizer\n",
        "\n",
        "    def train_model(self, train_loader):\n",
        "\n",
        "        self.model_config()\n",
        "\n",
        "        for epoch in range(1, self.num_epochs + 1, 1):\n",
        "\n",
        "            print(f'epoch:{epoch}')\n",
        "\n",
        "            for batch, (data, targets) in enumerate(train_loader):\n",
        "\n",
        "                data = data.to(device=self.device)\n",
        "                targets = targets.to(device=self.device)\n",
        "\n",
        "                if not self._model_name.startswith('vit'):\n",
        "                    data = data.repeat(1, 3, 1, 1)\n",
        "                else:\n",
        "                    data = data.repeat(1, 3, 8, 8)\n",
        "\n",
        "                scores = self.model(data)\n",
        "                loss = self.criterion(scores, targets)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "                self.optimizer.step()\n",
        "\n",
        "    def _check_acc(self, loader):\n",
        "        if loader.dataset.train:\n",
        "            print('Checking accuracy on training data')\n",
        "        else:\n",
        "            print('Checking accuracy o test data')\n",
        "        num_correct = 0\n",
        "        num_samples = 0\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in loader:\n",
        "                x = x.to(device=self.device)\n",
        "                y = y.to(device=self.device)\n",
        "\n",
        "                if not self._model_name.startswith('vit'):\n",
        "                    x = x.repeat(1, 3, 1, 1)\n",
        "                else:\n",
        "                    x = x.repeat(1, 3, 8, 8)\n",
        "\n",
        "                scores = self.model(x)\n",
        "                _, predictions = scores.max(1)\n",
        "                num_correct += (predictions == y).sum()\n",
        "                num_samples += predictions.size(0)\n",
        "\n",
        "            print(\n",
        "                f'Got {num_correct}/{num_samples} with accuracy {(float(num_correct) / float(num_samples)) * 100}')\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "    def check_accuracy(self, train_loader, test_loader):\n",
        "        self._check_acc(train_loader)\n",
        "        self._check_acc(test_loader)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzM3QhoQonIy"
      },
      "source": [
        "class MNIST:\n",
        "  def __init__(self, batch_size=2):\n",
        "    self.batch_size=batch_size\n",
        "    self._train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "    self._train_loader=DataLoader(dataset=self._train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    self._test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
        "    self._test_loader=DataLoader(dataset=self._test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "  def train_loader(self):\n",
        "    return self._train_loader\n",
        "  \n",
        "  def test_loader(self):\n",
        "    return self._test_loader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkkoCLZ9plfN"
      },
      "source": [
        "model = TimmModel('vit_tiny_patch16_224')\n",
        "mnist = MNIST()\n",
        "\n",
        "train_loader = mnist.train_loader()\n",
        "test_loader = mnist.test_loader()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGZrdFuLqT4e",
        "outputId": "a4bbe518-d674-43ab-b3b5-b3baa19cfa9b"
      },
      "source": [
        "model.train_model(train_loader=train_loader)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1\n",
            "epoch:2\n",
            "epoch:3\n",
            "epoch:4\n",
            "epoch:5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwH8HzzuGgnQ",
        "outputId": "40619755-7e13-4c0b-d23c-9c55f27eaf98"
      },
      "source": [
        "model.check_accuracy(train_loader, test_loader)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on training data\n",
            "Got 43494/60000 with accuracy 72.49\n",
            "Checking accuracy o test data\n",
            "Got 7228/10000 with accuracy 72.28\n"
          ]
        }
      ]
    }
  ]
}