{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c410c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5b0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dir = 'speech-command-classification/'\n",
    "audio_dir = s_dir+'audio_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ae1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(s_dir+'sample_submission.csv')\n",
    "test_df['file_name'] = audio_dir + test_df['file_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830b1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(s_dir+'train.csv')\n",
    "\n",
    "train_df['file_name'] = audio_dir + train_df['file_name'].astype(str)\n",
    "\n",
    "id = 0\n",
    "class_to_id = {}\n",
    "id_to_class = {}\n",
    "\n",
    "for cl_name in train_df['target']:\n",
    "    if cl_name not in class_to_id.keys():\n",
    "        class_to_id[cl_name] = id\n",
    "        id+=1\n",
    "\n",
    "\n",
    "for cl_name, cl_id in class_to_id.items():\n",
    "    if cl_id not in id_to_class.keys():\n",
    "        id_to_class[cl_id] = cl_name\n",
    "        \n",
    "\n",
    "train_df['num_target'] = [class_to_id[cl_name] for cl_name in train_df['target']]\n",
    "\n",
    "\n",
    "data = train_df\n",
    "\n",
    "train_data, val_data = train_test_split(data,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab3f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDS(Dataset):\n",
    "    def __init__(self, file_paths, train_mode=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.duration = 1000\n",
    "        self.sr = 16000\n",
    "        self.n_fft = 1024\n",
    "        self.hop_length = None\n",
    "        self.n_mels = 64\n",
    "        self.top_db = 80\n",
    "        self.train_mode=train_mode\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        file_path = self.file_paths.iloc[[idx]].values[0][0]\n",
    "       \n",
    "        \n",
    "        samples, sr = torchaudio.load(file_path)\n",
    "        samples = self._pad_trunc(samples, self.sr)\n",
    "        \n",
    "        spect = torchaudio.transforms.MelSpectrogram(\n",
    "            self.sr,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            n_mels=self.n_mels\n",
    "        )(samples)\n",
    "        \n",
    "\n",
    "        spect = torchaudio.transforms.AmplitudeToDB(top_db=self.top_db)(spect)\n",
    "\n",
    "        spect = self.rechannel(spect, self.sr, 3)\n",
    "        \n",
    "#         print(self.train_mode)\n",
    "        \n",
    "        if self.train_mode:           \n",
    "            class_id = self.file_paths.iloc[[idx]].values[0][2]\n",
    "            return spect, class_id\n",
    "        \n",
    "        return spect\n",
    "\n",
    "\n",
    "\n",
    "    def _pad_trunc(self, samples, sr):\n",
    "        num_rows, signal_len = samples.shape\n",
    "        max_len = sr // 1000 * self.duration\n",
    "\n",
    "        if (signal_len > max_len):\n",
    "            # Truncate the signal to the given length\n",
    "            samples = samples[:, max_len]\n",
    "\n",
    "        elif (signal_len < max_len):\n",
    "            # Length of padding to add at the beginning and end of the signal\n",
    "            pad_begin_len = random.randint(0, max_len - signal_len)\n",
    "            pad_end_len = max_len - signal_len - pad_begin_len\n",
    "\n",
    "            # Pad with 0s\n",
    "            pad_begin = torch.zeros((1, pad_begin_len))\n",
    "            pad_end = torch.zeros((1, pad_end_len))\n",
    "\n",
    "            samples = torch.cat((pad_begin, samples, pad_end), 1)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def rechannel(self, spect, sr, num_channel):\n",
    "        if (spect.shape[0] == num_channel):\n",
    "            # Nothing to do\n",
    "            return spect\n",
    "\n",
    "        if (num_channel == 1):\n",
    "            # Convert from stereo to mono by selecting only the first channel\n",
    "            spect = spect[:1, :]\n",
    "        else:\n",
    "            # Convert from mono to stereo by duplicating the first channel\n",
    "            spect = torch.cat([spect, spect, spect])\n",
    "\n",
    "        return spect\n",
    "\n",
    "    def _time_shift(self, samples, sr, shift_limit):\n",
    "        _, sig_len = samples.shape\n",
    "        shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "        return samples.roll(shift_amt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0570c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SoundDS(file_paths=train_data)\n",
    "valid_dataset = SoundDS(file_paths=val_data)\n",
    "test_dataset = SoundDS(file_paths=test_df, train_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0bdc406",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088b9413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=35, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu' \n",
    "\n",
    "model = models.resnet18()\n",
    "n_inputs=model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 35), \n",
    "                      nn.ReLU(),\n",
    ")\n",
    "\n",
    "# model.load_state_dict(torch.load('models/resnet50.pt'))\n",
    "# model.eval()\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b754207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1bb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c58ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Val Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358fd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.637887  [    0/59264]\n",
      "loss: 2.667962  [12800/59264]\n",
      "loss: 2.089060  [25600/59264]\n",
      "loss: 1.641281  [38400/59264]\n",
      "loss: 1.241233  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 68.3%, Avg loss: 1.236901 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.873310  [    0/59264]\n",
      "loss: 1.188784  [12800/59264]\n",
      "loss: 0.976807  [25600/59264]\n",
      "loss: 1.403313  [38400/59264]\n",
      "loss: 0.919188  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 72.3%, Avg loss: 1.046289 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.795661  [    0/59264]\n",
      "loss: 0.824849  [12800/59264]\n",
      "loss: 1.130418  [25600/59264]\n",
      "loss: 1.039290  [38400/59264]\n",
      "loss: 1.006916  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.973522 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.708033  [    0/59264]\n",
      "loss: 0.646970  [12800/59264]\n",
      "loss: 0.978067  [25600/59264]\n",
      "loss: 0.823096  [38400/59264]\n",
      "loss: 0.905363  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.941668 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.891858  [    0/59264]\n",
      "loss: 0.432465  [12800/59264]\n",
      "loss: 0.796578  [25600/59264]\n",
      "loss: 0.695825  [38400/59264]\n",
      "loss: 0.646386  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.922591 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.818870  [    0/59264]\n",
      "loss: 0.569805  [12800/59264]\n",
      "loss: 0.607677  [25600/59264]\n",
      "loss: 0.677373  [38400/59264]\n",
      "loss: 0.723434  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.928052 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.511514  [    0/59264]\n",
      "loss: 0.676411  [12800/59264]\n",
      "loss: 0.447273  [25600/59264]\n",
      "loss: 0.636458  [38400/59264]\n",
      "loss: 0.701627  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.944426 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.702245  [    0/59264]\n",
      "loss: 0.533396  [12800/59264]\n",
      "loss: 0.646038  [25600/59264]\n",
      "loss: 0.501121  [38400/59264]\n",
      "loss: 0.472758  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.912056 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.634558  [    0/59264]\n",
      "loss: 0.478282  [12800/59264]\n",
      "loss: 0.494806  [25600/59264]\n",
      "loss: 0.551634  [38400/59264]\n",
      "loss: 0.645544  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.967063 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.393020  [    0/59264]\n",
      "loss: 0.689406  [12800/59264]\n",
      "loss: 0.704090  [25600/59264]\n",
      "loss: 0.659678  [38400/59264]\n",
      "loss: 0.742850  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.933401 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.474398  [    0/59264]\n",
      "loss: 0.529454  [12800/59264]\n",
      "loss: 0.520014  [25600/59264]\n",
      "loss: 0.757018  [38400/59264]\n",
      "loss: 0.604713  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.874002 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.437789  [    0/59264]\n",
      "loss: 0.381636  [12800/59264]\n",
      "loss: 0.384924  [25600/59264]\n",
      "loss: 0.543983  [38400/59264]\n",
      "loss: 0.704469  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.867104 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.508782  [    0/59264]\n",
      "loss: 0.583220  [12800/59264]\n",
      "loss: 0.449490  [25600/59264]\n",
      "loss: 0.569740  [38400/59264]\n",
      "loss: 0.489759  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.864497 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.418440  [    0/59264]\n",
      "loss: 0.507971  [12800/59264]\n",
      "loss: 0.398853  [25600/59264]\n",
      "loss: 0.408058  [38400/59264]\n",
      "loss: 0.489895  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.863220 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.548606  [    0/59264]\n",
      "loss: 0.481756  [12800/59264]\n",
      "loss: 0.515774  [25600/59264]\n",
      "loss: 0.566324  [38400/59264]\n",
      "loss: 0.542851  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.868003 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.648658  [    0/59264]\n",
      "loss: 0.552264  [12800/59264]\n",
      "loss: 0.549400  [25600/59264]\n",
      "loss: 0.581616  [38400/59264]\n",
      "loss: 0.623422  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.874464 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.506867  [    0/59264]\n",
      "loss: 0.490168  [12800/59264]\n",
      "loss: 0.472365  [25600/59264]\n",
      "loss: 0.544372  [38400/59264]\n",
      "loss: 0.525095  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.872486 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.593894  [    0/59264]\n",
      "loss: 0.528421  [12800/59264]\n",
      "loss: 0.451671  [25600/59264]\n",
      "loss: 0.449609  [38400/59264]\n",
      "loss: 0.654008  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.876469 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.365574  [    0/59264]\n",
      "loss: 0.338133  [12800/59264]\n",
      "loss: 0.614912  [25600/59264]\n",
      "loss: 0.339856  [38400/59264]\n",
      "loss: 0.513869  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.878157 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.590726  [    0/59264]\n",
      "loss: 0.606840  [12800/59264]\n",
      "loss: 0.586018  [25600/59264]\n",
      "loss: 0.568142  [38400/59264]\n",
      "loss: 0.568722  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.878587 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.656393  [    0/59264]\n",
      "loss: 0.808651  [12800/59264]\n",
      "loss: 0.501866  [25600/59264]\n",
      "loss: 0.367626  [38400/59264]\n",
      "loss: 0.453718  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.876233 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.549377  [    0/59264]\n",
      "loss: 0.448492  [12800/59264]\n",
      "loss: 0.502391  [25600/59264]\n",
      "loss: 0.499072  [38400/59264]\n",
      "loss: 0.395903  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.874735 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.475952  [    0/59264]\n",
      "loss: 0.701836  [12800/59264]\n",
      "loss: 0.562647  [25600/59264]\n",
      "loss: 0.448468  [38400/59264]\n",
      "loss: 0.533214  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.873421 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.335518  [    0/59264]\n",
      "loss: 0.679513  [12800/59264]\n",
      "loss: 0.447140  [25600/59264]\n",
      "loss: 0.537723  [38400/59264]\n",
      "loss: 0.491621  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.874526 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.536983  [    0/59264]\n",
      "loss: 0.612802  [12800/59264]\n",
      "loss: 0.584419  [25600/59264]\n",
      "loss: 0.579112  [38400/59264]\n",
      "loss: 0.591621  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.873541 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.448152  [    0/59264]\n",
      "loss: 0.480084  [12800/59264]\n",
      "loss: 0.475494  [25600/59264]\n",
      "loss: 0.671441  [38400/59264]\n",
      "loss: 0.502134  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.872900 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.418407  [    0/59264]\n",
      "loss: 0.402437  [12800/59264]\n",
      "loss: 0.514101  [25600/59264]\n",
      "loss: 0.497230  [38400/59264]\n",
      "loss: 0.530760  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.871971 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.529874  [    0/59264]\n",
      "loss: 0.597464  [12800/59264]\n",
      "loss: 0.514094  [25600/59264]\n",
      "loss: 0.576332  [38400/59264]\n",
      "loss: 0.446518  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.872650 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 29\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.509539  [    0/59264]\n",
      "loss: 0.588643  [12800/59264]\n",
      "loss: 0.502320  [25600/59264]\n",
      "loss: 0.567757  [38400/59264]\n",
      "loss: 0.588521  [51200/59264]\n",
      "Val Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.874132 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.738439  [    0/59264]\n",
      "loss: 0.619769  [12800/59264]\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    validation(val_dataloader, model, loss_fn)\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), 'models/resnet18_30e.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "717a5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'models/resnet50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b11e71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = []\n",
    "# model.eval()\n",
    "for batch, X in enumerate(test_dataloader):\n",
    "    X= X.to(device)\n",
    "    pred = model(X)\n",
    "    for row in pred.detach().numpy():\n",
    "        preds.append(np.argmax(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a037e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_classes = []\n",
    "\n",
    "for idx in preds:\n",
    "    res_classes.append(id_to_class[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "593161c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv(s_dir+'sample_submission.csv')\n",
    "res_df['target'] = res_classes\n",
    "res_df.to_csv(r'submission5.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
